# ===================================================
# BeZhas Web3 - Production Docker Compose
# ===================================================
# This configuration is optimized for production deployments
# ===================================================

version: '3.8'

services:
  # ===== MongoDB Primary =====
  mongo:
    image: mongo:6.0
    restart: always
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USER:-bezhas_admin}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD}
      MONGO_INITDB_DATABASE: bezhas
    volumes:
      - mongo-data:/data/db
      - mongo-config:/data/configdb
      - ./scripts/mongo-init.js:/docker-entrypoint-initdb.d/init.js:ro
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    networks:
      - bezhas-network
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2'
        reservations:
          memory: 512M

  # ===== Redis for Caching and Queues =====
  redis:
    image: redis:7-alpine
    restart: always
    ports:
      - "6379:6379"
    command: >
      redis-server
      --appendonly yes
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 30s
      timeout: 5s
      retries: 3
    networks:
      - bezhas-network
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1'

  # ===== Backend API =====
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.optimized
    restart: always
    ports:
      - "3001:3001"
    environment:
      - NODE_ENV=production
      - PORT=3001
      - MONGODB_URI=mongodb://${MONGO_USER}:${MONGO_PASSWORD}@mongo:27017/bezhas?authSource=admin
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - JWT_SECRET=${JWT_SECRET}
      - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY}
      - STRIPE_WEBHOOK_SECRET=${STRIPE_WEBHOOK_SECRET}
      - RPC_URL=${RPC_URL}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GOOGLE_AI_API_KEY=${GOOGLE_AI_API_KEY}
      - FRONTEND_URL=${FRONTEND_URL:-https://bezhas.com}
      - LOG_LEVEL=${LOG_LEVEL:-info}
    depends_on:
      mongo:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - bezhas-network
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 1G
          cpus: '2'
        reservations:
          memory: 512M
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      rollback_config:
        parallelism: 1
        delay: 10s

  # ===== Frontend =====
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.optimized
      args:
        - VITE_API_URL=${VITE_API_URL:-https://api.bezhas.com}
        - VITE_WS_URL=${VITE_WS_URL:-wss://api.bezhas.com}
        - VITE_CHAIN_ID=${VITE_CHAIN_ID:-137}
        - VITE_NETWORK=${VITE_NETWORK:-polygon}
    restart: always
    ports:
      - "80:80"
    depends_on:
      - backend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/"]
      interval: 30s
      timeout: 3s
      retries: 3
    networks:
      - bezhas-network
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
      update_config:
        parallelism: 1
        delay: 10s

  # ===== Nginx Load Balancer (Optional) =====
  nginx:
    image: nginx:1.25-alpine
    restart: always
    ports:
      - "443:443"
    volumes:
      - ./nginx/nginx.prod.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - frontend
      - backend
    networks:
      - bezhas-network
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.25'
    profiles:
      - with-nginx

  # ===== TimescaleDB for Analytics (Optional) =====
  timescaledb:
    image: timescale/timescaledb:latest-pg14
    restart: always
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-bezhas}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=bezhas_analytics
    volumes:
      - timescale-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-bezhas}"]
      interval: 30s
      timeout: 5s
      retries: 3
    networks:
      - bezhas-network
    profiles:
      - with-analytics

  # ===== Prometheus Monitoring (Optional) =====
  prometheus:
    image: prom/prometheus:latest
    restart: always
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
    networks:
      - bezhas-network
    profiles:
      - with-monitoring

  # ===== Grafana Dashboard (Optional) =====
  grafana:
    image: grafana/grafana:latest
    restart: always
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
    depends_on:
      - prometheus
    networks:
      - bezhas-network
    profiles:
      - with-monitoring

networks:
  bezhas-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

volumes:
  mongo-data:
    driver: local
  mongo-config:
    driver: local
  redis-data:
    driver: local
  timescale-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
